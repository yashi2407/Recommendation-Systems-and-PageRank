{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1l-mB_5Wap4C",
        "outputId": "2664fe92-1a91-49bc-990a-af2f36903224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "PageRank Results for: graph-full.txt\n",
            "Top 10 nodes by PageRank:\n",
            "Node 263: 0.002020\n",
            "Node 537: 0.001943\n",
            "Node 965: 0.001925\n",
            "Node 243: 0.001853\n",
            "Node 285: 0.001827\n",
            "Node 255: 0.001802\n",
            "Node 126: 0.001801\n",
            "Node 502: 0.001800\n",
            "Node 16: 0.001792\n",
            "Node 747: 0.001785\n",
            "\n",
            "Bottom 10 nodes by PageRank:\n",
            "Node 558: 0.000329\n",
            "Node 93: 0.000351\n",
            "Node 62: 0.000353\n",
            "Node 424: 0.000355\n",
            "Node 408: 0.000388\n",
            "Node 742: 0.000393\n",
            "Node 81: 0.000407\n",
            "Node 920: 0.000411\n",
            "Node 657: 0.000428\n",
            "Node 386: 0.000432\n",
            "\n",
            "PageRank Results for: graph-small.txt\n",
            "Top 10 nodes by PageRank:\n",
            "Node 53: 0.035731\n",
            "Node 14: 0.034171\n",
            "Node 40: 0.033630\n",
            "Node 1: 0.030006\n",
            "Node 27: 0.029720\n",
            "Node 66: 0.029195\n",
            "Node 48: 0.025397\n",
            "Node 79: 0.019613\n",
            "Node 61: 0.019180\n",
            "Node 65: 0.019117\n",
            "\n",
            "Bottom 10 nodes by PageRank:\n",
            "Node 85: 0.003410\n",
            "Node 59: 0.003670\n",
            "Node 81: 0.003695\n",
            "Node 37: 0.003808\n",
            "Node 89: 0.003922\n",
            "Node 84: 0.004036\n",
            "Node 23: 0.004124\n",
            "Node 94: 0.004248\n",
            "Node 50: 0.004258\n",
            "Node 7: 0.004274\n",
            "\n",
            "Sanity Check — Top Node ID: 53, Score: 0.035731\n",
            "Expected: Node 53 with score ~0.036\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext\n",
        "\n",
        "def run_pagerank(file_path, is_sanity_check=False):\n",
        "    sc = SparkContext(appName=\"PageRank\")\n",
        "    beta = 0.8\n",
        "    iterations = 40\n",
        "\n",
        "    # Load and parse edges (deduplicate)\n",
        "    data = sc.textFile(file_path)\n",
        "    edges = data.map(lambda line: tuple(map(int, line.strip().split()))).distinct()\n",
        "\n",
        "    # Get all nodes\n",
        "    nodes = edges.flatMap(lambda x: x).distinct()\n",
        "    n = nodes.count()\n",
        "\n",
        "    # Adjacency list and out-degrees\n",
        "    outlinks = edges.groupByKey().mapValues(set).cache()\n",
        "    out_degrees = outlinks.mapValues(len).collectAsMap()\n",
        "    out_degree_broadcast = sc.broadcast(out_degrees)\n",
        "\n",
        "    # Initial PageRank vector\n",
        "    ranks = nodes.map(lambda node: (node, 1.0 / n)).cache()\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        contribs = outlinks.join(ranks).flatMap(\n",
        "            lambda node_data: [\n",
        "                (dst, node_data[1][1] / out_degree_broadcast.value[node_data[0]])\n",
        "                for dst in node_data[1][0]\n",
        "            ]\n",
        "        )\n",
        "        ranks = contribs.reduceByKey(lambda x, y: x + y).mapValues(\n",
        "            lambda sum_rank: ((1 - beta) / n) + beta * sum_rank\n",
        "        ).cache()\n",
        "\n",
        "    # Collect results\n",
        "    final_ranks = ranks.collect()\n",
        "    top_10 = sorted(final_ranks, key=lambda x: -x[1])[:10]\n",
        "    bottom_10 = sorted(final_ranks, key=lambda x: x[1])[:10]\n",
        "\n",
        "    # Output\n",
        "    print(f\"\\nPageRank Results for: {file_path}\")\n",
        "    print(\"Top 10 nodes by PageRank:\")\n",
        "    for node, score in top_10:\n",
        "        print(f\"Node {node}: {score:.6f}\")\n",
        "\n",
        "    print(\"\\nBottom 10 nodes by PageRank:\")\n",
        "    for node, score in bottom_10:\n",
        "        print(f\"Node {node}: {score:.6f}\")\n",
        "\n",
        "    # Optional sanity check\n",
        "    if is_sanity_check:\n",
        "        top_node = top_10[0]\n",
        "        print(f\"\\nSanity Check — Top Node ID: {top_node[0]}, Score: {top_node[1]:.6f}\")\n",
        "        print(\"Expected: Node 53 with score ~0.036\")\n",
        "\n",
        "    sc.stop()\n",
        "\n",
        "# ---------- Run Either Dataset ----------\n",
        "# Run with graph-full.txt\n",
        "run_pagerank(\"graph-full.txt\")\n",
        "\n",
        "# Run with graph-small.txt (sanity check)\n",
        "run_pagerank(\"graph-small.txt\", is_sanity_check=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}